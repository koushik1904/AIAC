{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnEoGZYnjynVkqu/v9uNay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brahmani1237/Ai_Assisted_coding_lab_3/blob/main/Lab%2023.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1 – Project Proposal\n",
        "•\tStudents choose a real-world problem to solve with an AI-assisted application (e.g., e-commerce billing system, health monitoring dashboard, student attendance tracker).\n",
        "•\tPrepare a project proposal including:\n",
        "o\tObjective\n",
        "o\tFeatures\n",
        "o\tTools/technologies to be used\n",
        "o\tExpected output\n"
      ],
      "metadata": {
        "id": "fLGtKGC_5nyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : Design and implement an AI-powered personalized health dashboard that uses time series analysis and a Generative AI coach to monitor real-time biometrics, predict burnout risk, and deliver tailored wellness recommendations."
      ],
      "metadata": {
        "id": "zqU11FX9631Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py - Backend Server Logic (using Flask)\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Assume a database connector is initialized here (e.g., db_connect)\n",
        "\n",
        "@app.route('/api/v1/data/ingest', methods=['POST'])\n",
        "def ingest_wearable_data():\n",
        "    \"\"\"Receives and validates JSON payload of wearable data.\"\"\"\n",
        "    if not request.is_json:\n",
        "        return jsonify({\"msg\": \"Missing JSON in request\"}), 400\n",
        "\n",
        "    data = request.get_json()\n",
        "\n",
        "    # 1. Basic validation check for essential fields\n",
        "    required_fields = ['user_id', 'recorded_at', 'heart_rate_bpm', 'sleep_duration_hrs']\n",
        "    if not all(field in data for field in required_fields):\n",
        "        return jsonify({\"msg\": \"Missing one or more required data fields\"}), 400\n",
        "\n",
        "    try:\n",
        "        # 2. Call the database function to insert data\n",
        "        insert_into_wearable_data(\n",
        "            data['user_id'],\n",
        "            data['recorded_at'],\n",
        "            data['heart_rate_bpm'],\n",
        "            data.get('hrv_ms'), # HRV is optional/may not always be available\n",
        "            data['sleep_duration_hrs']\n",
        "        )\n",
        "        # 3. Trigger the ML model asynchronously after data ingestion\n",
        "        # trigger_ml_prediction_pipeline(data['user_id'])\n",
        "\n",
        "        return jsonify({\"msg\": \"Data ingested successfully\", \"status\": \"ok\"}), 201\n",
        "\n",
        "    except Exception as e:\n",
        "        # 4. Error handling\n",
        "        print(f\"Database error: {e}\")\n",
        "        return jsonify({\"msg\": \"Internal server error during data storage\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Use a port like 5000 for development\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb6BPQ9A7F4S",
        "outputId": "641b2c91-f44e-4b20-a0e6-886bc8e0a403"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : Certainly! This code defines a basic Flask backend application, app.py, which is responsible for ingesting wearable biometric data. Let me break down its key components:\n",
        "\n",
        "Flask Application Setup: It initializes a Flask application.\n",
        "/api/v1/data/ingest Endpoint: This is a POST route (@app.route('/api/v1/data/ingest', methods=['POST'])) designed to receive JSON payloads of wearable data.\n",
        "Data Validation: When data is received, it first checks if the request contains JSON. Then, it validates if essential fields like user_id, recorded_at, heart_rate_bpm, and sleep_duration_hrs are present in the JSON payload.\n",
        "Database Interaction (Placeholder): There's a commented-out call to insert_into_wearable_data, indicating where the ingested data would typically be stored in a database. It also mentions an optional hrv_ms field.\n",
        "ML Model Trigger (Placeholder): A commented-out line trigger_ml_prediction_pipeline(data['user_id']) suggests that after successful data ingestion, an asynchronous machine learning prediction pipeline would be triggered for the specific user.\n",
        "Error Handling: It includes error handling for cases like missing JSON, missing required data fields, or internal server errors during data storage.\n",
        "Development Server: The if __name__ == '__main__': app.run(debug=True) block makes the Flask application runnable directly, typically on http://127.0.0.1:5000 in development mode.\n"
      ],
      "metadata": {
        "id": "9xtg1pAY7W3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2 – Application Design\n",
        "•\tUse AI tools to assist in:\n",
        "o\tDesigning system architecture diagrams.\n",
        "o\tDefining database schema (if needed).\n",
        "o\tCreating wireframes/UI mockups for frontend design.\n"
      ],
      "metadata": {
        "id": "cmixx0QU7b82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT :Generate the system architecture (3-tier cloud model), the core SQL database schema (User, WearableData, AIPrediction tables), and low-fidelity mobile wireframes for the main dashboard and AI chat interface for the 'AI-Powered Personalized Health & Wellness Coach' application.\""
      ],
      "metadata": {
        "id": "ToxlNeOc7py6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d1b11f2",
        "outputId": "43e5dcf8-02c0-4339-a6e8-10577e7507b3"
      },
      "source": [
        "# SQL Schema Definition\n",
        "sql_schema = \"\"\"\n",
        "-- Table: public.User\n",
        "CREATE TABLE IF NOT EXISTS public.\"User\"\n",
        "(\n",
        "    user_id SERIAL PRIMARY KEY,\n",
        "    username VARCHAR(50) UNIQUE NOT NULL,\n",
        "    email VARCHAR(100) UNIQUE NOT NULL,\n",
        "    password_hash VARCHAR(255) NOT NULL,\n",
        "    created_at TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n",
        "    last_login_at TIMESTAMP WITHOUT TIME ZONE\n",
        ");\n",
        "\n",
        "-- Table: public.WearableData\n",
        "CREATE TABLE IF NOT EXISTS public.\"WearableData\"\n",
        "(\n",
        "    data_id SERIAL PRIMARY KEY,\n",
        "    user_id INTEGER NOT NULL,\n",
        "    recorded_at TIMESTAMP WITHOUT TIME ZONE NOT NULL,\n",
        "    heart_rate_bpm INTEGER NOT NULL,\n",
        "    hrv_ms FLOAT,\n",
        "    sleep_duration_hrs FLOAT NOT NULL,\n",
        "    steps INTEGER,\n",
        "    calories_burned INTEGER,\n",
        "    distance_km FLOAT,\n",
        "    FOREIGN KEY (user_id) REFERENCES public.\"User\"(user_id) ON DELETE CASCADE\n",
        ");\n",
        "\n",
        "-- Table: public.AIPrediction\n",
        "CREATE TABLE IF NOT EXISTS public.\"AIPrediction\"\n",
        "(\n",
        "    prediction_id SERIAL PRIMARY KEY,\n",
        "    user_id INTEGER NOT NULL,\n",
        "    prediction_timestamp TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n",
        "    burnout_risk_score FLOAT,\n",
        "    wellness_score FLOAT,\n",
        "    recommendation_text TEXT,\n",
        "    prediction_model_version VARCHAR(50),\n",
        "    FOREIGN KEY (user_id) REFERENCES public.\"User\"(user_id) ON DELETE CASCADE\n",
        ");\n",
        "\n",
        "-- Optional: Add indexes for performance if needed\n",
        "-- CREATE INDEX idx_wearable_user_recorded ON public.\"WearableData\" (user_id, recorded_at);\n",
        "-- CREATE INDEX idx_prediction_user_timestamp ON public.\"AIPrediction\" (user_id, prediction_timestamp);\n",
        "\"\"\"\n",
        "\n",
        "print(\"Generated SQL Database Schema for User, WearableData, and AIPrediction tables.\")\n",
        "print(sql_schema)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated SQL Database Schema for User, WearableData, and AIPrediction tables.\n",
            "\n",
            "-- Table: public.User\n",
            "CREATE TABLE IF NOT EXISTS public.\"User\"\n",
            "(\n",
            "    user_id SERIAL PRIMARY KEY,\n",
            "    username VARCHAR(50) UNIQUE NOT NULL,\n",
            "    email VARCHAR(100) UNIQUE NOT NULL,\n",
            "    password_hash VARCHAR(255) NOT NULL,\n",
            "    created_at TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n",
            "    last_login_at TIMESTAMP WITHOUT TIME ZONE\n",
            ");\n",
            "\n",
            "-- Table: public.WearableData\n",
            "CREATE TABLE IF NOT EXISTS public.\"WearableData\"\n",
            "(\n",
            "    data_id SERIAL PRIMARY KEY,\n",
            "    user_id INTEGER NOT NULL,\n",
            "    recorded_at TIMESTAMP WITHOUT TIME ZONE NOT NULL,\n",
            "    heart_rate_bpm INTEGER NOT NULL,\n",
            "    hrv_ms FLOAT,\n",
            "    sleep_duration_hrs FLOAT NOT NULL,\n",
            "    steps INTEGER,\n",
            "    calories_burned INTEGER,\n",
            "    distance_km FLOAT,\n",
            "    FOREIGN KEY (user_id) REFERENCES public.\"User\"(user_id) ON DELETE CASCADE\n",
            ");\n",
            "\n",
            "-- Table: public.AIPrediction\n",
            "CREATE TABLE IF NOT EXISTS public.\"AIPrediction\"\n",
            "(\n",
            "    prediction_id SERIAL PRIMARY KEY,\n",
            "    user_id INTEGER NOT NULL,\n",
            "    prediction_timestamp TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n",
            "    burnout_risk_score FLOAT,\n",
            "    wellness_score FLOAT,\n",
            "    recommendation_text TEXT,\n",
            "    prediction_model_version VARCHAR(50),\n",
            "    FOREIGN KEY (user_id) REFERENCES public.\"User\"(user_id) ON DELETE CASCADE\n",
            ");\n",
            "\n",
            "-- Optional: Add indexes for performance if needed\n",
            "-- CREATE INDEX idx_wearable_user_recorded ON public.\"WearableData\" (user_id, recorded_at);\n",
            "-- CREATE INDEX idx_prediction_user_timestamp ON public.\"AIPrediction\" (user_id, prediction_timestamp);\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : Certainly! The selected code defines the SQL schema for three tables: User, WearableData, and AIPrediction. These tables are foundational for storing information in your AI-Powered Personalized Health & Wellness Coach application.\n",
        "\n",
        "The User table stores basic user information like username, email, and password_hash, along with created_at and last_login_at timestamps.\n",
        "The WearableData table is designed to store the biometric data collected from users, such as heart_rate_bpm, hrv_ms, sleep_duration_hrs, steps, calories_burned, and distance_km. It includes a user_id as a foreign key to link data to specific users and recorded_at to timestamp each entry.\n",
        "The AIPrediction table will store the outputs from your AI models. This includes a burnout_risk_score, wellness_score, recommendation_text, and the prediction_model_version. This table also links back to the User table via user_id and records when the prediction was made (prediction_timestamp).\n",
        "Each table uses SERIAL PRIMARY KEY for automatic ID generation and FOREIGN KEY constraints to maintain data integrity between them. The CREATE TABLE IF NOT EXISTS syntax ensures that the tables are only created if they don't already exist.\n",
        "\n"
      ],
      "metadata": {
        "id": "fjzX_E_A8eIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3 – AI-Assisted Code Development\n",
        "•\tImplement the application in phases:\n",
        "o\tFrontend: Web/mobile UI with HTML/CSS/JS (or framework).\n",
        "o\tBackend: RESTful APIs or server logic.\n",
        "o\tDatabase: Schema design, SQL queries.\n",
        "o\tIntegration: API calls, authentication, error handling\n"
      ],
      "metadata": {
        "id": "2VlLyKV78ozI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : Generate foundational, language-agnostic code templates for the 'AI-Powered Health Coach' application, including:\n",
        "\n",
        "A RESTful Backend Endpoint (Python/Flask or similar structure) for /api/v1/data/ingest to receive JSON wearable data and save it.\n",
        "\n",
        "A basic SQL function to insert data into the WearableData table.\n",
        "\n",
        "A Frontend JavaScript fetch request to call the ingestion endpoint.\n",
        "\n",
        "A simple HTML/CSS template for the main Dashboard view with placeholders for the 'Wellness Score' and 'Chat with AI Coach' button.\""
      ],
      "metadata": {
        "id": "oZ2gf2uX9NTa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e847d27",
        "outputId": "adfd023b-5bc4-4421-b080-52a7deac76d4"
      },
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Assume a database connector is initialized here (e.g., db_connect)\n",
        "\n",
        "def insert_into_wearable_data(user_id, recorded_at, heart_rate_bpm, hrv_ms, sleep_duration_hrs):\n",
        "    \"\"\"Placeholder function to simulate data insertion into WearableData table.\"\"\"\n",
        "    print(f\"Simulating data insertion for User {user_id}: Recorded at={recorded_at}, Heart Rate={heart_rate_bpm}, HRV={hrv_ms}, Sleep={sleep_duration_hrs}hrs\")\n",
        "    # In a real application, this would connect to a database and execute an INSERT query.\n",
        "    return True\n",
        "\n",
        "@app.route('/api/v1/data/ingest', methods=['POST'])\n",
        "def ingest_wearable_data():\n",
        "    \"\"\"Receives and validates JSON payload of wearable data.\"\"\"\n",
        "    if not request.is_json:\n",
        "        return jsonify({\"msg\": \"Missing JSON in request\"}), 400\n",
        "\n",
        "    data = request.get_json()\n",
        "\n",
        "    # 1. Basic validation check for essential fields\n",
        "    required_fields = ['user_id', 'recorded_at', 'heart_rate_bpm', 'sleep_duration_hrs']\n",
        "    if not all(field in data for field in required_fields):\n",
        "        return jsonify({\"msg\": \"Missing one or more required data fields\"}), 400\n",
        "\n",
        "    try:\n",
        "        # 2. Call the database function to insert data\n",
        "        insert_into_wearable_data(\n",
        "            data['user_id'],\n",
        "            data['recorded_at'],\n",
        "            data['heart_rate_bpm'],\n",
        "            data.get('hrv_ms'), # HRV is optional/may not always be available\n",
        "            data['sleep_duration_hrs']\n",
        "        )\n",
        "        # 3. Trigger the ML model asynchronously after data ingestion\n",
        "        # trigger_ml_prediction_pipeline(data['user_id'])\n",
        "\n",
        "        return jsonify({\"msg\": \"Data ingested successfully\", \"status\": \"ok\"}), 201\n",
        "\n",
        "    except Exception as e:\n",
        "        # 4. Error handling\n",
        "        print(f\"Database error: {e}\")\n",
        "        return jsonify({\"msg\": \"Internal server error during data storage\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Use a port like 5000 for development\n",
        "    app.run(debug=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : Certainly! The selected code defines a basic Flask backend application. Let me break down its key components:\n",
        "\n",
        "Flask Application Setup: It initializes a Flask application.\n",
        "insert_into_wearable_data function: This is a placeholder function that simulates saving data to a database. In a real application, this function would contain the actual logic to connect to a database and insert the wearable data.\n",
        "/api/v1/data/ingest Endpoint: This is a POST route (@app.route('/api/v1/data/ingest', methods=['POST'])) designed to receive JSON payloads of wearable data.\n",
        "Data Validation: When data is received, the endpoint first checks if the request contains JSON. Then, it validates if essential fields like user_id, recorded_at, heart_rate_bpm, and sleep_duration_hrs are present in the JSON payload.\n",
        "Database Interaction (Simulated): It calls the insert_into_wearable_data function to simulate storing the ingested data. It also mentions an optional hrv_ms field.\n",
        "ML Model Trigger (Placeholder): A commented-out line trigger_ml_prediction_pipeline(data['user_id']) suggests that after successful data ingestion, an asynchronous machine learning prediction pipeline would be triggered for the specific user.\n",
        "Error Handling: It includes error handling for cases like missing JSON, missing required data fields, or internal server errors during data storage.\n",
        "Development Server: The if __name__ == '__main__': app.run(debug=True) block makes the Flask application runnable directly, typically on http://127.0.0.1:5000 in development mode.\n"
      ],
      "metadata": {
        "id": "jQ-pBpzW-mes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4 – Documentation & Code Quality\n",
        "•\tGenerate automatic documentation and inline comments using AI.\n",
        "•\tEnsure clear README.md for project setup and usage.\n",
        "•\tConduct AI-assisted code review to refine readability and maintainability\n"
      ],
      "metadata": {
        "id": "YeXNIcKX9Y_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : \"Generate a comprehensive README.md for the AI Health Coach project, including setup, usage, and database instructions.\"\"Review the Python Flask API code for PEP 8 compliance and suggest security improvements against SQL injection risks.\"\"Add Sphinx-style docstrings and inline comments to the core functions of the Flask backend and the SQL schema."
      ],
      "metadata": {
        "id": "-Cg3Vy1e9dcR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f7d442b",
        "outputId": "56b2a607-2ea0-4d7a-f5ed-c01a028da83a"
      },
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Assume a database connector is initialized here (e.g., db_connect)\n",
        "# This is a placeholder for actual database connection logic.\n",
        "\n",
        "def insert_into_wearable_data(user_id, recorded_at, heart_rate_bpm, hrv_ms, sleep_duration_hrs):\n",
        "    \"\"\"Simulates data insertion into the WearableData table.\n",
        "\n",
        "    This function is a placeholder for actual database interaction. In a real application,\n",
        "    it would connect to a database (e.g., PostgreSQL) and execute an INSERT query to store\n",
        "    the provided wearable data.\n",
        "\n",
        "    :param user_id: The ID of the user whose data is being recorded.\n",
        "    :type user_id: int\n",
        "    :param recorded_at: The timestamp when the data was recorded.\n",
        "    :type recorded_at: str\n",
        "    :param heart_rate_bpm: The user's heart rate in beats per minute.\n",
        "    :type heart_rate_bpm: int\n",
        "    :param hrv_ms: Heart Rate Variability in milliseconds (optional).\n",
        "    :type hrv_ms: float or None\n",
        "    :param sleep_duration_hrs: The duration of sleep in hours.\n",
        "    :type sleep_duration_hrs: float\n",
        "    :returns: True if the simulation was successful.\n",
        "    :rtype: bool\n",
        "    \"\"\"\n",
        "    print(f\"Simulating data insertion for User {user_id}: Recorded at={recorded_at}, Heart Rate={heart_rate_bpm}, HRV={hrv_ms}, Sleep={sleep_duration_hrs}hrs\")\n",
        "    # In a real application, this would connect to a database and execute an INSERT query.\n",
        "    # Example: db_connect.execute(\"INSERT INTO WearableData (...) VALUES (...) \")\n",
        "    return True\n",
        "\n",
        "@app.route('/api/v1/data/ingest', methods=['POST'])\n",
        "def ingest_wearable_data():\n",
        "    \"\"\"Receives and validates JSON payload of wearable data.\n",
        "\n",
        "    This endpoint handles incoming wearable biometric data from devices or frontend applications.\n",
        "    It performs basic validation, simulates database insertion, and provides error handling.\n",
        "\n",
        "    :requebody: JSON object with user biometric data.\n",
        "    :requejson user_id: User identifier (int).\n",
        "    :requejson recorded_at: Timestamp of data recording (str).\n",
        "    :requejson heart_rate_bpm: Heart rate in beats per minute (int).\n",
        "    :requejson sleep_duration_hrs: Sleep duration in hours (float).\n",
        "    :optionjson hrv_ms: Heart Rate Variability in milliseconds (float).\n",
        "    :status 201: Data ingested successfully.\n",
        "    :status 400: Missing JSON in request or missing required data fields.\n",
        "    :status 500: Internal server error during data storage.\n",
        "    :returns: A JSON response indicating the status of the data ingestion.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "    # Check if the incoming request contains JSON data\n",
        "    if not request.is_json:\n",
        "        return jsonify({\"msg\": \"Missing JSON in request\"}), 400\n",
        "\n",
        "    # Parse the JSON data from the request body\n",
        "    data = request.get_json()\n",
        "\n",
        "    # 1. Basic validation check for essential fields\n",
        "    required_fields = ['user_id', 'recorded_at', 'heart_rate_bpm', 'sleep_duration_hrs']\n",
        "    if not all(field in data for field in required_fields):\n",
        "        # Return an error if any required field is missing\n",
        "        return jsonify({\"msg\": \"Missing one or more required data fields\"}), 400\n",
        "\n",
        "    try:\n",
        "        # 2. Call the database function (simulated) to insert data\n",
        "        insert_into_wearable_data(\n",
        "            data['user_id'],\n",
        "            data['recorded_at'],\n",
        "            data['heart_rate_bpm'],\n",
        "            data.get('hrv_ms'), # HRV is optional and retrieved using .get() to avoid KeyError\n",
        "            data['sleep_duration_hrs']\n",
        "        )\n",
        "        # 3. Trigger the ML model asynchronously after data ingestion (placeholder)\n",
        "        # This function call would initiate a separate process or queue a task\n",
        "        # to process the newly ingested data for predictions.\n",
        "        # trigger_ml_prediction_pipeline(data['user_id'])\n",
        "\n",
        "        # Return success response if data is ingested\n",
        "        return jsonify({\"msg\": \"Data ingested successfully\", \"status\": \"ok\"}), 201\n",
        "\n",
        "    except Exception as e:\n",
        "        # 4. Error handling for any exceptions during data processing or storage\n",
        "        print(f\"Database error: {e}\") # Log the error for debugging purposes\n",
        "        return jsonify({\"msg\": \"Internal server error during data storage\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Run the Flask application in debug mode for development purposes.\n",
        "    # In a production environment, a WSGI server like Gunicorn or uWSGI would be used.\n",
        "    app.run(debug=True)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : Certainly! This code defines a Flask backend application for ingesting wearable biometric data. It's an improved version of the previous code, now featuring comprehensive Sphinx-style docstrings and inline comments for better readability and maintainability. Let's break it down:\n",
        "\n",
        "Flask Application Setup: It initializes the Flask application instance, app.\n",
        "insert_into_wearable_data function: This function now includes a detailed Sphinx-style docstring explaining its purpose as a placeholder for database interaction, its parameters (user_id, recorded_at, heart_rate_bpm, hrv_ms, sleep_duration_hrs), and its return type. Inline comments further clarify the simulated nature of the data insertion.\n",
        "/api/v1/data/ingest Endpoint: This is a POST route designed to receive JSON payloads of wearable data. It also has a Sphinx-style docstring detailing its role, request body parameters (including required and optional fields), and possible HTTP status codes. Inline comments walk through each step of the endpoint's logic.\n",
        "Data Validation: The endpoint first checks if the request contains JSON. Then, it validates if essential fields (user_id, recorded_at, heart_rate_bpm, sleep_duration_hrs) are present in the JSON payload, returning a 400 error if any are missing.\n",
        "Database Interaction (Simulated): It calls the insert_into_wearable_data function to simulate storing the ingested data. The use of data.get('hrv_ms') is commented to explain handling optional fields.\n",
        "ML Model Trigger (Placeholder): A commented-out line (trigger_ml_prediction_pipeline) suggests where an asynchronous machine learning prediction pipeline would be triggered after successful data ingestion.\n",
        "Error Handling: It includes a try-except block to catch general exceptions during data processing or storage, logging the error and returning a 500 internal server error.\n",
        "Development Server: The if __name__ == '__main__': app.run(debug=True) block allows the Flask application to be run directly, typically on http://127.0.0.1:5000 in development mode, with a comment advising on production deployment.\n"
      ],
      "metadata": {
        "id": "rCFPG5pg-sct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 – Testing & Debugging\n",
        "•\tUse AI to:\n",
        "o\tGenerate unit tests.\n",
        "o\tIdentify vulnerabilities/security flaws.\n",
        "o\tSuggest optimizations for performance.\n"
      ],
      "metadata": {
        "id": "9GfRZz3X-1SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : Testing & Debugging • Use AI to:  Generate unit tests.  Identify vulnerabilities/security flaws. o Suggest optimizations for performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "-Rka0QSX-40V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "111a161a",
        "outputId": "d91f6e6a-7f5f-4e35-9d24-ade20cc5d61d"
      },
      "source": [
        "import unittest\n",
        "import json\n",
        "from flask import Flask\n",
        "\n",
        "# Assuming your Flask app and insert_into_wearable_data function are in a file named `app_with_docs.py` or accessible in the current context.\n",
        "# For this example, we'll directly import the app and the placeholder function.\n",
        "# In a real scenario, you might structure your project to import from a specific module.\n",
        "\n",
        "# Re-define the app and insert_into_wearable_data for testing context if not already accessible\n",
        "# This assumes the code from cell `5f7d442b` has been run and `app` and `insert_into_wearable_data` are in scope.\n",
        "\n",
        "# --- Start of placeholder definitions (if running this cell independently) ---\n",
        "# If the app and function are already defined globally from previous cells,\n",
        "# you can comment out these re-definitions.\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def insert_into_wearable_data(user_id, recorded_at, heart_rate_bpm, hrv_ms, sleep_duration_hrs):\n",
        "    # print(f\"Simulating data insertion for User {user_id}: Recorded at={recorded_at}, Heart Rate={heart_rate_bpm}, HRV={hrv_ms}, Sleep={sleep_duration_hrs}hrs\")\n",
        "    return True\n",
        "\n",
        "@app.route('/api/v1/data/ingest', methods=['POST'])\n",
        "def ingest_wearable_data():\n",
        "    if not request.is_json:\n",
        "        return jsonify({\"msg\": \"Missing JSON in request\"}), 400\n",
        "\n",
        "    data = request.get_json()\n",
        "\n",
        "    required_fields = ['user_id', 'recorded_at', 'heart_rate_bpm', 'sleep_duration_hrs']\n",
        "    if not all(field in data for field in required_fields):\n",
        "        return jsonify({\"msg\": \"Missing one or more required data fields\"}), 400\n",
        "\n",
        "    try:\n",
        "        insert_into_wearable_data(\n",
        "            data['user_id'],\n",
        "            data['recorded_at'],\n",
        "            data['heart_rate_bpm'],\n",
        "            data.get('hrv_ms'),\n",
        "            data['sleep_duration_hrs']\n",
        "        )\n",
        "        return jsonify({\"msg\": \"Data ingested successfully\", \"status\": \"ok\"}), 201\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "        return jsonify({\"msg\": \"Internal server error during data storage\"}), 500\n",
        "# --- End of placeholder definitions ---\n",
        "\n",
        "\n",
        "class TestIngestWearableData(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up test client for the Flask app.\"\"\"\n",
        "        self.app = app.test_client()\n",
        "        self.app.testing = True # Enable testing mode\n",
        "\n",
        "    def test_ingest_wearable_data_success(self):\n",
        "        \"\"\"Test successful data ingestion with all required fields.\"\"\"\n",
        "        data = {\n",
        "            \"user_id\": 123,\n",
        "            \"recorded_at\": \"2023-10-27T10:00:00Z\",\n",
        "            \"heart_rate_bpm\": 75,\n",
        "            \"sleep_duration_hrs\": 7.5,\n",
        "            \"hrv_ms\": 50.2\n",
        "        }\n",
        "        response = self.app.post('/api/v1/data/ingest', data=json.dumps(data), content_type='application/json')\n",
        "        self.assertEqual(response.status_code, 201)\n",
        "        self.assertEqual(json.loads(response.data)['msg'], \"Data ingested successfully\")\n",
        "\n",
        "    def test_ingest_wearable_data_missing_json(self):\n",
        "        \"\"\"Test data ingestion without a JSON payload.\"\"\"\n",
        "        response = self.app.post('/api/v1/data/ingest', data='not json data', content_type='text/plain')\n",
        "        self.assertEqual(response.status_code, 400)\n",
        "        self.assertEqual(json.loads(response.data)['msg'], \"Missing JSON in request\")\n",
        "\n",
        "    def test_ingest_wearable_data_missing_required_field(self):\n",
        "        \"\"\"Test data ingestion with a missing required field (e.g., heart_rate_bpm).\"\"\"\n",
        "        data = {\n",
        "            \"user_id\": 123,\n",
        "            \"recorded_at\": \"2023-10-27T10:00:00Z\",\n",
        "            \"sleep_duration_hrs\": 7.5\n",
        "        } # heart_rate_bpm is missing\n",
        "        response = self.app.post('/api/v1/data/ingest', data=json.dumps(data), content_type='application/json')\n",
        "        self.assertEqual(response.status_code, 400)\n",
        "        self.assertEqual(json.loads(response.data)['msg'], \"Missing one or more required data fields\")\n",
        "\n",
        "    def test_ingest_wearable_data_internal_server_error(self):\n",
        "        \"\"\"Test handling of an internal server error during data storage (simulated).\"\"\"\n",
        "        # Temporarily break the insert_into_wearable_data function to simulate an error\n",
        "        original_insert = globals()['insert_into_wearable_data']\n",
        "        def faulty_insert(*args, **kwargs):\n",
        "            raise Exception(\"Simulated database error\")\n",
        "        globals()['insert_into_wearable_data'] = faulty_insert\n",
        "\n",
        "        data = {\n",
        "            \"user_id\": 123,\n",
        "            \"recorded_at\": \"2023-10-27T10:00:00Z\",\n",
        "            \"heart_rate_bpm\": 75,\n",
        "            \"sleep_duration_hrs\": 7.5\n",
        "        }\n",
        "        response = self.app.post('/api/v1/data/ingest', data=json.dumps(data), content_type='application/json')\n",
        "        self.assertEqual(response.status_code, 500)\n",
        "        self.assertEqual(json.loads(response.data)['msg'], \"Internal server error during data storage\")\n",
        "\n",
        "        # Restore the original function\n",
        "        globals()['insert_into_wearable_data'] = original_insert\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "....\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.021s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database error: Simulated database error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : Certainly! The selected code defines a set of unit tests for the Flask /api/v1/data/ingest endpoint using Python's unittest framework. Let's break down its components:\n",
        "\n",
        "Flask App and Function Redefinition: At the top, the Flask app and the insert_into_wearable_data placeholder function are redefined. This is done to ensure the test environment has a consistent and isolated version of the Flask application logic to test against, especially if the cell is run independently. The insert_into_wearable_data function is simplified to just return True for testing purposes, as the tests are focused on the API's behavior, not the actual database interaction.\n",
        "\n",
        "TestIngestWearableData Class: This class inherits from unittest.TestCase, providing a structured way to define multiple tests.\n",
        "\n",
        "setUp Method: This method is run before each test function. It initializes a test_client() for the Flask application. This client allows simulating HTTP requests to the Flask app without actually running the server, making testing efficient.\n",
        "\n",
        "test_ingest_wearable_data_success: This test case simulates a successful POST request to /api/v1/data/ingest with all required data fields and an optional hrv_ms. It asserts that the response status code is 201 (Created) and the message indicates successful ingestion.\n",
        "\n",
        "test_ingest_wearable_data_missing_json: This test sends a request with non-JSON content. It asserts that the API correctly returns a 400 (Bad Request) status code and the appropriate error message for missing JSON.\n",
        "\n",
        "test_ingest_wearable_data_missing_required_field: This test sends JSON data but intentionally omits a required field (heart_rate_bpm). It verifies that the API responds with a 400 status code and an error message indicating missing required fields.\n",
        "\n",
        "test_ingest_wearable_data_internal_server_error: This test is more advanced. It temporarily replaces the insert_into_wearable_data function with a faulty_insert that raises an exception. This simulates a database error. The test then asserts that the API catches this error and returns a 500 (Internal Server Error) status code, with a message indicating an internal server error during data storage. Crucially, it restores the original function afterward to prevent side effects on other tests.\n",
        "\n",
        "if __name__ == '__main__': unittest.main(...): This block allows you to run the tests directly when the script is executed. argv=['first-arg-is-ignored'] and exit=False are often used in interactive environments like notebooks to prevent unittest.main() from trying to parse command-line arguments or exiting the interpreter"
      ],
      "metadata": {
        "id": "gTsNSlLC_eGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6 – Deployment & Presentation\n",
        "•\tDeploy application on a cloud/free hosting platform (Heroku, GitHub Pages, Firebase, etc.).\n",
        "•\tPrepare a final presentation including:\n",
        "o\tProblem statement\n",
        "o\tSolution architecture\n",
        "o\tLive demo\n",
        "o\tReflection on AI assistance and limitations\n"
      ],
      "metadata": {
        "id": "bCR-r6kW_jcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : Generate a step-by-step deployment guide for the Python/Flask backend API and the HTML/JS frontend of the 'AI Health Coach' application using Heroku and GitHub Pages, respectively.\""
      ],
      "metadata": {
        "id": "0iFuLMbD_nYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py snippet for production readiness\n",
        "import os\n",
        "from flask import Flask\n",
        "\n",
        "# ... other imports\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Heroku sets the DATABASE_URL environment variable automatically for the add-on\n",
        "DATABASE_URL = os.environ.get('DATABASE_URL')\n",
        "# Configure your database connection (using a library like SQLAlchemy or psycopg2)\n",
        "# e.g., if using SQLAlchemy:\n",
        "# app.config['SQLALCHEMY_DATABASE_URI'] = DATABASE_URL"
      ],
      "metadata": {
        "id": "sktbMQH3AS1_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION:Certainly! The selected code is a Python snippet designed to enhance a Flask application for production deployment. It focuses on how to securely and flexibly manage database connections. Specifically, it retrieves the DATABASE_URL from environment variables, which is a standard practice on cloud hosting platforms like Heroku, where database add-ons automatically set this variable. The commented-out line then shows how you would typically use this DATABASE_URL to configure a database ORM, such as SQLAlchemy, within your Flask application. This approach ensures that sensitive database credentials are not hardcoded directly into the application, promoting better security and portability across different environments.\n",
        "\n"
      ],
      "metadata": {
        "id": "MAOx2_kxAdWm"
      }
    }
  ]
}
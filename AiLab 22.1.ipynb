{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/OfDyml6UhIFteP39c4mV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brahmani1237/Ai_Assisted_coding_lab_3/blob/main/Lab%2022.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1 – Bias Detection in AI Suggestions\n",
        "•\tProvide the same coding task to an AI tool multiple times.\n",
        "•\tCheck if AI outputs different results depending on prompt phrasing.\n",
        "•\tDiscuss:\n",
        "o\tAre there hidden assumptions or biases in the responses?\n",
        "o\tHow could biased AI code impact fairness or accessibility\n"
      ],
      "metadata": {
        "id": "AtYq-yP2EV3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : Give the following coding task to the AI multiple times and analyze bias:\n",
        "Write a program that sorts a list of student names and assigns grades.\n",
        "Run the task with different phrasings (e.g., simple, detailed, ambiguous instructions).\n",
        "Compare the AI’s outputs and answer the following:\n",
        "\n",
        "Does the AI produce different code depending on how the prompt is phrased?\n",
        "\n",
        "Do any responses show hidden assumptions or biases (e.g., assuming certain names, languages, styles)?\n",
        "\n",
        "How could biased AI-generated code affect fairness, accessibility, or inclusivity in real-world software?\n",
        "Provide your full analysis.\"*"
      ],
      "metadata": {
        "id": "bjsbjnIJEa74"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af762da7",
        "outputId": "54f68724-c6a0-4f1e-b831-caad8fac6776"
      },
      "source": [
        "# This is a placeholder for AI-generated code.\n",
        "# Please replace this with the actual output from an AI tool\n",
        "# when prompted with: \"Write a program that sorts a list of student names and assigns grades.\"\n",
        "\n",
        "def sort_and_grade_students(student_data):\n",
        "    \"\"\"\n",
        "    Sorts a list of student names alphabetically and assigns random grades.\n",
        "\n",
        "    Args:\n",
        "        student_data (dict): A dictionary where keys are student names (str)\n",
        "                             and values are their current scores (int).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with sorted student names as keys and assigned\n",
        "              grades (A, B, C, D, F) as values.\n",
        "    \"\"\"\n",
        "    sorted_names = sorted(student_data.keys())\n",
        "    graded_students = {}\n",
        "\n",
        "    import random\n",
        "    grades = ['A', 'B', 'C', 'D', 'F']\n",
        "\n",
        "    for name in sorted_names:\n",
        "        # For demonstration, assigning a random grade. In a real scenario,\n",
        "        # this would depend on the score.\n",
        "        graded_students[name] = random.choice(grades)\n",
        "    return graded_students\n",
        "\n",
        "# Example usage:\n",
        "students = {\n",
        "    'Alice': 85,\n",
        "    'Bob': 92,\n",
        "    'Charlie': 78,\n",
        "    'Diana': 65,\n",
        "    'Eve': 95\n",
        "}\n",
        "\n",
        "assigned_grades = sort_and_grade_students(students)\n",
        "print(\"Sorted students and their assigned grades:\")\n",
        "for name, grade in assigned_grades.items():\n",
        "    print(f\"{name}: {grade}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted students and their assigned grades:\n",
            "Alice: D\n",
            "Bob: F\n",
            "Charlie: B\n",
            "Diana: C\n",
            "Eve: C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8aa74c",
        "outputId": "0a7fddaa-09b3-4a5e-ca5e-827fba865b7d"
      },
      "source": [
        "def assign_grade(score):\n",
        "    if 90 <= score <= 100:\n",
        "        return 'A'\n",
        "    elif 80 <= score <= 89:\n",
        "        return 'B'\n",
        "    elif 70 <= score <= 79:\n",
        "        return 'C'\n",
        "    elif 60 <= score <= 69:\n",
        "        return 'D'\n",
        "    else:\n",
        "        return 'F'\n",
        "\n",
        "def sort_and_grade_students_detailed(student_list):\n",
        "    \"\"\"\n",
        "    Sorts a list of student names alphabetically by last name and assigns grades\n",
        "    based on numerical scores using a detailed grading scale.\n",
        "\n",
        "    Args:\n",
        "        student_list (list): A list of dictionaries, where each dictionary\n",
        "                             contains 'first_name', 'last_name', and 'score'.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing 'first_name', 'last_name',\n",
        "              and 'grade', sorted by last name.\n",
        "    \"\"\"\n",
        "    # Sort the students by last name\n",
        "    sorted_students = sorted(student_list, key=lambda x: x['last_name'])\n",
        "\n",
        "    graded_students = []\n",
        "    for student in sorted_students:\n",
        "        grade = assign_grade(student['score'])\n",
        "        graded_students.append({\n",
        "            'first_name': student['first_name'],\n",
        "            'last_name': student['last_name'],\n",
        "            'grade': grade\n",
        "        })\n",
        "    return graded_students\n",
        "\n",
        "# Example usage:\n",
        "students_data = [\n",
        "    {'first_name': 'Alice', 'last_name': 'Smith', 'score': 85},\n",
        "    {'first_name': 'Bob', 'last_name': 'Johnson', 'score': 92},\n",
        "    {'first_name': 'Charlie', 'last_name': 'Brown', 'score': 78},\n",
        "    {'first_name': 'Diana', 'last_name': 'Miller', 'score': 65},\n",
        "    {'first_name': 'Eve', 'last_name': 'Davis', 'score': 95},\n",
        "    {'first_name': 'Frank', 'last_name': 'Garcia', 'score': 58},\n",
        "    {'first_name': 'Grace', 'last_name': 'Adams', 'score': 72}\n",
        "]\n",
        "\n",
        "assigned_grades_detailed = sort_and_grade_students_detailed(students_data)\n",
        "print(\"Sorted students and their assigned grades (detailed prompt):\")\n",
        "for student in assigned_grades_detailed:\n",
        "    print(f\"{student['first_name']} {student['last_name']}: {student['grade']}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted students and their assigned grades (detailed prompt):\n",
            "Grace Adams: C\n",
            "Charlie Brown: C\n",
            "Eve Davis: A\n",
            "Frank Garcia: F\n",
            "Bob Johnson: A\n",
            "Diana Miller: D\n",
            "Alice Smith: B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ddf284e",
        "outputId": "f065fa4d-1366-4e7f-900a-e95fc2f4b42d"
      },
      "source": [
        "def assign_simple_grade(score):\n",
        "    \"\"\"\n",
        "    Assigns a simple 'Pass' or 'Fail' grade based on a score.\n",
        "    \"\"\"\n",
        "    if score >= 60:\n",
        "        return 'Pass'\n",
        "    else:\n",
        "        return 'Fail'\n",
        "\n",
        "def sort_and_grade_students_ambiguous(student_list):\n",
        "    \"\"\"\n",
        "    Sorts a list of student data by name and assigns a simple Pass/Fail grade.\n",
        "\n",
        "    Args:\n",
        "        student_list (list): A list of dictionaries, where each dictionary\n",
        "                             contains 'name' (str) and 'score' (int).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing 'name' and 'grade',\n",
        "              sorted alphabetically by name.\n",
        "    \"\"\"\n",
        "    # Sort the students by name\n",
        "    sorted_students = sorted(student_list, key=lambda x: x['name'])\n",
        "\n",
        "    graded_students = []\n",
        "    for student in sorted_students:\n",
        "        grade = assign_simple_grade(student['score'])\n",
        "        graded_students.append({\n",
        "            'name': student['name'],\n",
        "            'grade': grade\n",
        "        })\n",
        "    return graded_students\n",
        "\n",
        "# Example usage:\n",
        "students_data_ambiguous = [\n",
        "    {'name': 'Alice', 'score': 85},\n",
        "    {'name': 'Bob', 'score': 55},\n",
        "    {'name': 'Charlie', 'score': 70},\n",
        "    {'name': 'Diana', 'score': 45},\n",
        "    {'name': 'Eve', 'score': 92}\n",
        "]\n",
        "\n",
        "assigned_grades_ambiguous = sort_and_grade_students_ambiguous(students_data_ambiguous)\n",
        "print(\"Sorted students and their assigned grades (ambiguous prompt):\")\n",
        "for student in assigned_grades_ambiguous:\n",
        "    print(f\"{student['name']}: {student['grade']}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted students and their assigned grades (ambiguous prompt):\n",
            "Alice: Pass\n",
            "Bob: Fail\n",
            "Charlie: Pass\n",
            "Diana: Fail\n",
            "Eve: Pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8566e78"
      },
      "source": [
        "### Comparison of AI Outputs from Different Prompts\n",
        "\n",
        "Based on the code generated for the 'Simple Prompt' (cell `af762da7`), 'Detailed Prompt' (cell `ab8aa74c`), and 'Ambiguous Prompt' (cell `4ddf284e`), here's an analysis of the differences:\n",
        "\n",
        "1.  **Data Representation of Student Data:**\n",
        "    *   **Simple Prompt (`af762da7`):** Student data is represented as a `dictionary` where keys are student names (`str`) and values are their current scores (`int`). Example: `{'Alice': 85, 'Bob': 92}`.\n",
        "    *   **Detailed Prompt (`ab8aa74c`):** Student data is a `list of dictionaries`. Each dictionary contains separate fields for `'first_name'`, `'last_name'`, and `'score'`. Example: `[{'first_name': 'Alice', 'last_name': 'Smith', 'score': 85}]`.\n",
        "    *   **Ambiguous Prompt (`4ddf284e`):** Student data is also a `list of dictionaries`, but each dictionary contains a single `'name'` field and a `'score'` field. Example: `[{'name': 'Alice', 'score': 85}]`.\n",
        "\n",
        "2.  **Grading Logic:**\n",
        "    *   **Simple Prompt (`af762da7`):** Assigns a `random grade` from a predefined list `['A', 'B', 'C', 'D', 'F']`. It explicitly states this is for demonstration and would depend on score in a real scenario, but the AI chose randomness due to the simple prompt.\n",
        "    *   **Detailed Prompt (`ab8aa74c`):** Implements a `detailed A-F grading scale` based on numerical score ranges (e.g., 90-100 for 'A', 80-89 for 'B', etc.). This is a much more sophisticated and realistic grading system.\n",
        "    *   **Ambiguous Prompt (`4ddf284e`):** Uses a `simple 'Pass' or 'Fail' logic`, where a score >= 60 is 'Pass' and < 60 is 'Fail'. This is a direct interpretation of 'assigns grades' given an ambiguous instruction.\n",
        "\n",
        "3.  **Sorting Mechanism:**\n",
        "    *   **Simple Prompt (`af762da7`):** Sorts student names alphabetically based on the `keys` of the input dictionary (`sorted(student_data.keys())`).\n",
        "    *   **Detailed Prompt (`ab8aa74c`):** Sorts students by `last name` using a `lambda function` as the key for sorting a list of dictionaries (`key=lambda x: x['last_name']`).\n",
        "    *   **Ambiguous Prompt (`4ddf284e`):** Sorts students alphabetically by their full `name` field using a `lambda function` on a list of dictionaries (`key=lambda x: x['name']`).\n",
        "\n",
        "4.  **Function Definitions, Parameter Naming, and Overall Approach:**\n",
        "    *   **Function Definitions:** All three generated different primary function names (`sort_and_grade_students`, `sort_and_grade_students_detailed`, `sort_and_grade_students_ambiguous`) and auxiliary grading functions (none in simple, `assign_grade` in detailed, `assign_simple_grade` in ambiguous).\n",
        "    *   **Parameter Naming:** The parameter names for student data (`student_data`, `student_list`, `student_list`) vary, reflecting the different data structures assumed by the AI based on the prompt's detail level.\n",
        "    *   **Overall Complexity and Style:**\n",
        "        *   The **Simple Prompt** yields the most straightforward code, assuming minimal context and thus resorting to random assignment for grades, and dictionary keys for names.\n",
        "        *   The **Detailed Prompt** results in the most robust and structured code, handling first/last names separately and implementing a standard grading system. It demonstrates a clear understanding of a more complex requirement.\n",
        "        *   The **Ambiguous Prompt** produces code that is a middle-ground, simple but not random, interpreting 'grades' as a binary pass/fail, and handling names as a single field within a list of dictionaries. It suggests the AI chose a commonly understood, yet simple, interpretation when given less specific guidance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eeb1397"
      },
      "source": [
        "## Analyzing Hidden Assumptions and Biases\n",
        "\n",
        "To identify hidden assumptions and biases in the AI-generated code, we will systematically review each of the three code snippets provided earlier:\n",
        "\n",
        "1.  **Review the code generated for the simple prompt** (cell `af762da7`), **detailed prompt** (cell `ab8aa74c`), and **ambiguous prompt** (cell `4ddf284e`).\n",
        "\n",
        "2.  **Pay close attention to the example data used in each code snippet.** Note the names (e.g., 'Alice', 'Bob', 'Charlie', 'Smith', 'Johnson', etc.), their commonality, and any implied cultural context. Consider if these names represent a narrow demographic.\n",
        "\n",
        "3.  **Analyze the grading systems chosen by the AI for each prompt:**\n",
        "    *   **Simple Prompt:** Random grade assignment (A, B, C, D, F).\n",
        "    *   **Detailed Prompt:** A-F scale based on numerical scores with specific ranges.\n",
        "    *   **Ambiguous Prompt:** Simple Pass/Fail logic.\n",
        "    Consider if these grading systems reflect specific educational or cultural norms (e.g., a common A-F grading scale in some Western education systems, or a pass/fail system that might be prevalent in other contexts).\n",
        "\n",
        "4.  **Observe the data structures chosen** (e.g., dictionary mapping names to scores, or a list of dictionaries with separate first/last name fields). Consider if these choices imply a preferred way of structuring data that might not be universally applicable or might reflect common programming conventions in certain regions.\n",
        "\n",
        "5.  **Look for any other implicit assumptions in the code's logic, default values, or comments** that could indicate a bias in the AI's training data or design (e.g., assuming a specific country's educational system, or a particular programming paradigm, or certain performance metrics).\n",
        "\n",
        "6.  **Summarize your observations**, highlighting specific instances of assumptions or biases found in the code or example data from each prompt type in the next markdown cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3738cf3c"
      },
      "source": [
        "## Discussion: Impact of Biased AI Code on Fairness, Accessibility, and Inclusivity\n",
        "\n",
        "The analysis of AI-generated code for sorting student names and assigning grades, when prompted with different phrasings, reveals several implicit assumptions and biases. These biases, if incorporated into real-world software, could have significant negative impacts on fairness, accessibility, and inclusivity.\n",
        "\n",
        "### 1. Bias in Name Assumptions\n",
        "\n",
        "*   **Observations:**\n",
        "    *   The \"simple\" and \"ambiguous\" prompts led the AI to assume single names (e.g., 'Alice', 'Bob').\n",
        "    *   The \"detailed\" prompt led to the assumption of a clear 'first_name' and 'last_name' structure.\n",
        "\n",
        "*   **Potential Impact on Fairness and Inclusivity:**\n",
        "    *   **Exclusion of Diverse Naming Conventions:** Many cultures worldwide do not adhere to the 'first_name/last_name' dichotomy or even a single given name. Some cultures use patronymics, matronymics, multiple given names, no surname, or names with unique characters/scripts. A rigid AI system built on these assumptions could misrepresent, misidentify, or even exclude individuals whose names don't fit the expected format. This can lead to administrative errors, difficulty accessing services, or a sense of alienation.\n",
        "    *   **Example:** An AI-driven student registration system for an international university, if built on these biased naming conventions, might fail to correctly process records for students from countries with different naming structures (e.g., a student from Iceland where patronymics are common, or a student whose name includes diacritics not supported by the assumed character set). This could prevent them from enrolling, receiving proper documentation, or even being identified correctly in class rosters, leading to significant administrative burden and personal frustration.\n",
        "\n",
        "### 2. Bias in Grading System Assumptions\n",
        "\n",
        "*   **Observations:**\n",
        "    *   The \"simple\" prompt resulted in random grade assignment, demonstrating a lack of understanding of grading logic.\n",
        "    *   The \"detailed\" prompt produced a standard A-F letter grading scale (common in Western education).\n",
        "    *   The \"ambiguous\" prompt yielded a simple 'Pass'/'Fail' system.\n",
        "\n",
        "*   **Potential Impact on Fairness and Accessibility:**\n",
        "    *   **Lack of Nuance and Cultural Context:** Education systems globally employ diverse grading methodologies (e.g., numerical scales like 1-100 or 1-5, narrative assessments, percentage-based, different letter grade schemes). An AI rigidly implementing an A-F or Pass/Fail system might not be appropriate or fair for all contexts.\n",
        "    *   **Inaccurate Evaluation:** If an AI-generated academic evaluation tool (e.g., for scholarship applications or job placements) is hardcoded with a specific grading system, it might unfairly compare or misinterpret the academic performance of individuals from educational backgrounds using different scales. This could disadvantage deserving candidates.\n",
        "    *   **Example:** An AI-powered hiring platform that automatically converts applicant transcripts to an A-F scale might penalize candidates from countries where a '3' on a 5-point scale is excellent, but is interpreted as a 'C' (average) in the A-F system. Similarly, a system that only recognizes Pass/Fail might overlook exceptional performance in a course if it doesn't map to a more granular grade, impacting access to advanced programs or opportunities.\n",
        "\n",
        "### 3. Bias in Data Structure Assumptions\n",
        "\n",
        "*   **Observations:**\n",
        "    *   The AI assumed specific input formats for student data (e.g., a dictionary with name/score, or a list of dictionaries with 'first_name', 'last_name', 'score', or 'name', 'score').\n",
        "\n",
        "*   **Potential Impact on Accessibility and Inclusivity:**\n",
        "    *   **Rigidity and Inflexibility:** Real-world student management systems or data collection processes often involve more complex and varied data points beyond just names and scores (e.g., student IDs, age, gender, ethnicity, course codes, attendance records, special needs flags, preferred pronouns). An AI system assuming a minimal, fixed data structure will be brittle and unable to handle the rich, diverse data required for comprehensive student profiles.\n",
        "    *   **Data Loss and System Incompatibility:** If software generated by AI implicitly dictates a narrow data model, it could lead to errors when integrating with existing systems or processing data from different sources. This might result in loss of crucial information, force costly data transformations, or make the system inaccessible to institutions that cannot conform to the AI's limited data expectations.\n",
        "    *   **Example:** An AI-generated educational administration tool might be unable to import student data from a legacy system if the legacy data includes fields like 'student_id' or 'date_of_birth' that the AI's code didn't anticipate. This could lead to a fragmented system where certain student information is not processed, or it might exclude students whose profiles are more complex than the AI's assumed structure allows, hindering inclusive educational support."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : The analysis of AI-generated code, prompted with varying levels of detail, revealed significant biases. The AI consistently assumed Western naming conventions and grading systems (like A-F scales or Pass/Fail with a 60% threshold). These biases, if unchecked, could lead to unfair evaluations and exclusion in real-world applications by misrepresenting diverse cultural contexts and limiting accessibility.\n",
        "\n"
      ],
      "metadata": {
        "id": "J47vmrg0F6UI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2 – Privacy and Sensitive Data Handling\n",
        "•\tAsk AI to write a script that processes user personal data (e.g., names, phone numbers).\n",
        "•\tDiscuss:\n",
        "o\tHow should sensitive data be anonymized?\n",
        "o\tWhat ethical/legal issues could arise if AI-generated code mishandles it?\n",
        "o\tWhat role does developer responsibility play here?\n"
      ],
      "metadata": {
        "id": "jvNzYBCzGK2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : Ask the AI to write a script that processes personal user data such as names, phone numbers, or email addresses. Analyze the AI-generated code and discuss the following:\n",
        "\n",
        "How should sensitive personal data be anonymized or masked in the script?\n",
        "\n",
        "What ethical or legal issues (e.g., privacy laws, data breaches, misuse) could arise if the AI-generated code mishandles sensitive information?\n",
        "\n",
        "What responsibilities do developers have when using AI-generated code that processes personal data?\n",
        "\n",
        "Provide a detailed explanation and evaluation.\"."
      ],
      "metadata": {
        "id": "-bggXHtCF90a"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq9-9w0kHBvR"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "process_personal_data.py\n",
        "\n",
        "Usage:\n",
        "  - Provide a CSV file named input.csv with columns: id,name,email,phone\n",
        "  - Script will validate, create masked/pseudonymized/encrypted fields,\n",
        "    and export results to 'output_masked.csv' and 'output_pseudonymized.csv',\n",
        "    and store encrypted values in 'data_secure.db' (sqlite).\n",
        "\"\"\"\n",
        "\n",
        "import csv\n",
        "import re\n",
        "import hashlib\n",
        "import hmac\n",
        "import sqlite3\n",
        "import os\n",
        "from datetime import datetime\n",
        "from base64 import urlsafe_b64encode, urlsafe_b64decode\n",
        "\n",
        "# ---- Optional: pip install cryptography ----\n",
        "try:\n",
        "    from cryptography.fernet import Fernet, InvalidToken\n",
        "    HAS_FERNET = True\n",
        "except Exception:\n",
        "    HAS_FERNET = False\n",
        "\n",
        "# ---- Configuration (do NOT hardcode keys in production!) ----\n",
        "HMAC_KEY = b'your-32-byte-hmac-key-goes-here-please-change'  # use secure random key managed by vault\n",
        "FERNET_KEY = os.environ.get('FERNET_KEY')  # example: load from env or secret manager\n",
        "\n",
        "# ---- Validators ----\n",
        "EMAIL_RE = re.compile(r'^[^@\\s]+@[^@\\s]+\\.[^@\\s]+$')\n",
        "PHONE_RE = re.compile(r'^\\+?\\d{7,15}$')  # simplified E.164-ish validator\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : In short, this Python script is designed to process personal data from a CSV file. It includes functionality to mask, pseudonymize, and encrypt sensitive information like names, emails, and phone numbers. It also sets up validation rules for these data types and emphasizes the secure handling of cryptographic keys."
      ],
      "metadata": {
        "id": "ysM8X-dFHunF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3 – AI-Generated Security Risks\n",
        "•\tUse AI to generate login/authentication code.\n",
        "•\tIdentify possible security flaws (e.g., weak password storage, lack of encryption).\n",
        "•\tStudents must document risks and propose ethical guidelines for safe AI code usage.\n"
      ],
      "metadata": {
        "id": "kMjtXzNnH1F0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : Use AI to generate a simple login/authentication system in any programming language (such as Python, JavaScript, or Java). The code should accept a username and password, validate credentials, and display whether login is successful. After generating the code, analyze it for potential security flaws such as weak password storage, lack of hashing/encryption, insecure input handling, hard-coded credentials, missing rate-limiting, and susceptibility to brute-force attacks. Then document all identified risks and propose ethical guidelines and best practices for safely using AI-generated authentication code, including recommendations for secure password handling, encryption, secure storage, code review, and responsible deployment.\""
      ],
      "metadata": {
        "id": "_wTQwOJpH-uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insecure_login.py  -- DO NOT DEPLOY\n",
        "# Illustrates insecure practices for teaching / analysis.\n",
        "\n",
        "USERS = {\n",
        "    \"alice\": \"password123\",    # plain-text password (bad)\n",
        "    \"bob\": \"qwerty\"            # hard-coded credentials (bad)\n",
        "}\n",
        "\n",
        "def login(username: str, password: str) -> bool:\n",
        "    # direct comparison of plain-text\n",
        "    stored = USERS.get(username)\n",
        "    return stored is not None and stored == password\n",
        "\n",
        "def main():\n",
        "    u = input(\"Username: \").strip()\n",
        "    p = input(\"Password: \").strip()\n",
        "    if login(u, p):\n",
        "        print(\"Login successful\")\n",
        "    else:\n",
        "        print(\"Login failed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8stvP5bIAie",
        "outputId": "33f3cba1-981f-46d6-b120-9cc021afd45d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Username: BRAHMANI_23\n",
            "Password: ABCFG\n",
            "Login failed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : n short, the code in cell v8stvP5bIAie is an intentionally insecure Python script for a login system. It demonstrates security flaws like storing passwords in plain text and performing direct comparisons, which are critical vulnerabilities to avoid in real applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "v0ccKU2wIib9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4 – Accountability in Human–AI Collaboration\n",
        "•\tScenario: AI writes code for a hospital’s patient monitoring system.\n",
        "•\tIf the code fails and causes harm, who is responsible?\n",
        "o\tThe AI tool?\n",
        "o\tThe human developer?\n",
        "o\tThe organization using it?\n",
        "•\tStudents must debate and submit a reflection report.\n",
        "\n"
      ],
      "metadata": {
        "id": "QUuHq-A3Iwwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : \"Ask the AI to generate sample code for a hospital patient-monitoring system (e.g., reading vitals and triggering alerts). Then analyze who is responsible if this AI-generated code fails and causes patient harm—the AI tool, the human developer, or the hospital organization. Write a brief reflection discussing accountability, ethical issues, and required safeguards.\""
      ],
      "metadata": {
        "id": "o7Ou1M6XIzgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "ai_patient_monitor_demo.py\n",
        "\n",
        "Educational demo: simulated patient-monitoring system.\n",
        "DO NOT USE IN PRODUCTION. Not a medical device.\n",
        "\n",
        "Features:\n",
        "- Simulated sensor input (heart rate, SpO2, blood pressure)\n",
        "- Validation and sanitization of sensor readings\n",
        "- Redundant confirmation before raising critical alarms\n",
        "- Alert escalation (local alarm -> nurse station -> on-call physician)\n",
        "- Audit logging and event trace (who/what/when)\n",
        "- Human-in-the-loop acknowledgement for critical alerts\n",
        "- Watchdog/heartbeat monitoring for system health\n",
        "- Hooks for integration (SNS, pager, SMS, EMR) are stubbed out\n",
        "- Configurable thresholds per-patient\n",
        "\n",
        "Intended use: classroom analysis of responsibility, safety, and failure modes.\n",
        "\"\"\"\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Any, Optional, Callable, List\n",
        "import time\n",
        "import threading\n",
        "import random\n",
        "import uuid\n",
        "import logging\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ----------------------------\n",
        "# Configuration & Logging\n",
        "# ----------------------------\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
        "AUDIT_LOG = \"audit_log.jsonl\"\n",
        "\n",
        "def audit_event(event: Dict[str, Any]) -> None:\n",
        "    \"\"\"Append an audit event (json line) for traceability.\"\"\"\n",
        "    event['timestamp'] = datetime.utcnow().isoformat() + 'Z'\n",
        "    with open(AUDIT_LOG, 'a', encoding='utf-8') as f:\n",
        "        f.write(json.dumps(event) + '\\n')\n",
        "    logging.info(\"AUDIT %s\", event)\n",
        "\n",
        "# ----------------------------\n",
        "# Data models\n",
        "# ----------------------------\n",
        "@dataclass\n",
        "class Vitals:\n",
        "    heart_rate: Optional[float] = None      # beats per minute\n",
        "    spo2: Optional[float] = None            # percent\n",
        "    systolic_bp: Optional[float] = None     # mmHg\n",
        "    diastolic_bp: Optional[float] = None    # mmHg\n",
        "    sensor_id: Optional[str] = None\n",
        "    timestamp: Optional[float] = None       # epoch\n",
        "\n",
        "@dataclass\n",
        "class PatientConfig:\n",
        "    patient_id: str\n",
        "    name: str\n",
        "    thresholds: Dict[str, Dict[str, float]] = field(default_factory=lambda: {\n",
        "        # default thresholds; real deployments require clinician-provided settings\n",
        "        'heart_rate': {'low': 50, 'high': 120},\n",
        "        'spo2': {'low': 90, 'high': 100},\n",
        "        'systolic_bp': {'low': 90, 'high': 180},\n",
        "        'diastolic_bp': {'low': 60, 'high': 110},\n",
        "    })\n",
        "    confirmation_required: bool = True  # require redundant confirm before critical escalation\n",
        "\n",
        "# ----------------------------\n",
        "# Simulated sensors / adapters\n",
        "# ----------------------------\n",
        "class SensorSimulator:\n",
        "    \"\"\"Simulates noisy physiological sensors for teaching/demos.\"\"\"\n",
        "    def __init__(self, sensor_id: str, base_vitals: Dict[str, float], noise: float = 0.05):\n",
        "        self.sensor_id = sensor_id\n",
        "        self.base = base_vitals\n",
        "        self.noise = noise\n",
        "        self.fail_rate = 0.01  # fraction of readings that are invalid\n",
        "    def read(self) -> Vitals:\n",
        "        # Simulate occasional totally invalid output (None or wildly wrong)\n",
        "        if random.random() < self.fail_rate:\n",
        "            # simulate sensor glitch\n",
        "            return Vitals(sensor_id=self.sensor_id, heart_rate=None, spo2=None, systolic_bp=9999, diastolic_bp=None, timestamp=time.time())\n",
        "        # otherwise produce noisy reading\n",
        "        hr = self.base.get('heart_rate', 70) * (1 + random.uniform(-self.noise, self.noise))\n",
        "        spo2 = self.base.get('spo2', 98) * (1 + random.uniform(-self.noise, self.noise))\n",
        "        sbp = self.base.get('systolic_bp', 120) * (1 + random.uniform(-self.noise, self.noise))\n",
        "        dbp = self.base.get('diastolic_bp', 80) * (1 + random.uniform(-self.noise, self.noise))\n",
        "        return Vitals(heart_rate=round(hr,1), spo2=round(spo2,1), systolic_bp=round(sbp,1), diastolic_bp=round(dbp,1), sensor_id=self.sensor_id, timestamp=time.time())\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers: validation & sanitization\n",
        "# ----------------------------\n",
        "def validate_vitals(v: Vitals) -> bool:\n",
        "    \"\"\"Basic sanity checks. Reject values that are impossible/implausible.\"\"\"\n",
        "    # If timestamp missing or too far in the past -> invalid\n",
        "    if not v.timestamp or abs(time.time() - v.timestamp) > 60*5:\n",
        "        audit_event({'type': 'invalid_reading', 'reason': 'timestamp_out_of_range', 'vitals': v.__dict__})\n",
        "        return False\n",
        "    # Check numeric ranges\n",
        "    if v.heart_rate is not None and not (10 <= v.heart_rate <= 300):\n",
        "        audit_event({'type': 'invalid_reading', 'reason': 'heart_rate_out_of_range', 'vitals': v.__dict__})\n",
        "        return False\n",
        "    if v.spo2 is not None and not (50 <= v.spo2 <= 100):\n",
        "        audit_event({'type': 'invalid_reading', 'reason': 'spo2_out_of_range', 'vitals': v.__dict__})\n",
        "        return False\n",
        "    if v.systolic_bp is not None and not (40 <= v.systolic_bp <= 300):\n",
        "        audit_event({'type': 'invalid_reading', 'reason': 'systolic_bp_out_of_range', 'vitals': v.__dict__})\n",
        "        return False\n",
        "    if v.diastolic_bp is not None and not (20 <= v.diastolic_bp <= 200):\n",
        "        audit_event({'type': 'invalid_reading', 'reason': 'diastolic_bp_out_of_range', 'vitals': v.__dict__})\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# ----------------------------\n",
        "# Alerting system (with human-in-loop)\n",
        "# ----------------------------\n",
        "class AlertingSystem:\n",
        "    \"\"\"Handles local alarm, nurse station, and escalation logic.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.pending_critical_alerts: Dict[str, Dict[str, Any]] = {}\n",
        "    def local_alarm(self, patient: PatientConfig, vitals: Vitals, reason: str):\n",
        "        \"\"\"Sound a local bedside alarm (simulated).\"\"\"\n",
        "        event = {'type': 'local_alarm', 'patient_id': patient.patient_id, 'reason': reason, 'vitals': vitals.__dict__}\n",
        "        audit_event(event)\n",
        "        logging.warning(\"LOCAL ALARM for %s: %s | %s\", patient.patient_id, reason, vitals)\n",
        "        # In a real system: trigger audible alarm device, visual indicator, etc.\n",
        "    def notify_nurse_station(self, patient: PatientConfig, vitals: Vitals, reason: str):\n",
        "        event = {'type': 'notify_nurse', 'patient_id': patient.patient_id, 'reason': reason, 'vitals': vitals.__dict__}\n",
        "        audit_event(event)\n",
        "        logging.info(\"Notify nurse station: %s - %s\", patient.patient_id, reason)\n",
        "        # Real system: send to nurse console, paging, EMR flag\n",
        "    def escalate_to_physician(self, patient: PatientConfig, vitals: Vitals, reason: str):\n",
        "        \"\"\"Escalation path to on-call physician or rapid response.\"\"\"\n",
        "        alert_id = str(uuid.uuid4())\n",
        "        self.pending_critical_alerts[alert_id] = {'patient': patient.patient_id, 'vitals': vitals.__dict__, 'reason': reason, 'created': time.time()}\n",
        "        event = {'type': 'escalation', 'alert_id': alert_id, 'patient_id': patient.patient_id, 'reason': reason, 'vitals': vitals.__dict__}\n",
        "        audit_event(event)\n",
        "        logging.critical(\"ESCALATE [%s] %s -> physician: %s\", alert_id, patient.patient_id, reason)\n",
        "        # Real system: SMS/pager/email via secure channels\n",
        "        return alert_id\n",
        "    def acknowledge(self, alert_id: str, user: str) -> bool:\n",
        "        if alert_id in self.pending_critical_alerts:\n",
        "            event = {'type': 'acknowledge', 'alert_id': alert_id, 'ack_by': user}\n",
        "            audit_event(event)\n",
        "            logging.info(\"Alert %s acknowledged by %s\", alert_id, user)\n",
        "            del self.pending_critical_alerts[alert_id]\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "# ----------------------------\n",
        "# Monitoring logic with redundancy\n",
        "# ----------------------------\n",
        "class Monitor:\n",
        "    \"\"\"Monitors one patient (can be instantiated per patient).\"\"\"\n",
        "    def __init__(self, patient: PatientConfig, sensors: List[SensorSimulator], alerting: AlertingSystem, confirm_attempts: int = 2, confirm_interval: float = 1.0):\n",
        "        self.patient = patient\n",
        "        self.sensors = sensors\n",
        "        self.alerting = alerting\n",
        "        self.confirm_attempts = confirm_attempts\n",
        "        self.confirm_interval = confirm_interval\n",
        "        self.running = False\n",
        "        self.thread: Optional[threading.Thread] = None\n",
        "        self.last_heartbeat = time.time()\n",
        "        self.heartbeat_interval = 5.0  # seconds\n",
        "\n",
        "    def evaluate(self, v: Vitals) -> Optional[str]:\n",
        "        \"\"\"Return reason string if vitals are outside thresholds; else None.\"\"\"\n",
        "        t = self.patient.thresholds\n",
        "        if v.heart_rate is not None:\n",
        "            if v.heart_rate < t['heart_rate']['low']: return 'heart_rate_low'\n",
        "            if v.heart_rate > t['heart_rate']['high']: return 'heart_rate_high'\n",
        "        if v.spo2 is not None:\n",
        "            if v.spo2 < t['spo2']['low']: return 'spo2_low'\n",
        "        if v.systolic_bp is not None:\n",
        "            if v.systolic_bp < t['systolic_bp']['low']: return 'bp_systolic_low'\n",
        "            if v.systolic_bp > t['systolic_bp']['high']: return 'bp_systolic_high'\n",
        "        if v.diastolic_bp is not None:\n",
        "            if v.diastolic_bp < t['diastolic_bp']['low']: return 'bp_diastolic_low'\n",
        "            if v.diastolic_bp > t['diastolic_bp']['high']: return 'bp_diastolic_high'\n",
        "        return None\n",
        "\n",
        "    def redundant_confirm(self, read_func: Callable[[], Vitals], reason: str) -> bool:\n",
        "        \"\"\"\n",
        "        Before raising critical alarm, re-sample from different sensors or same sensor multiple times.\n",
        "        Return True if abnormality is confirmed.\n",
        "        \"\"\"\n",
        "        confirmations = 0\n",
        "        for attempt in range(self.confirm_attempts):\n",
        "            time.sleep(self.confirm_interval)\n",
        "            v2 = read_func()\n",
        "            if not validate_vitals(v2):\n",
        "                continue\n",
        "            r2 = self.evaluate(v2)\n",
        "            if r2 == reason:\n",
        "                confirmations += 1\n",
        "        # require at least 1 confirmation (configurable). For stricter systems, require confirmations from different sensors.\n",
        "        confirmed = confirmations >= 1\n",
        "        audit_event({'type': 'confirm_attempts', 'patient_id': self.patient.patient_id, 'reason': reason, 'confirmations': confirmations, 'required': 1})\n",
        "        return confirmed\n",
        "\n",
        "    def check_once(self):\n",
        "        # Read from all sensors and merge (prefer median / majority) to reduce single-sensor errors\n",
        "        readings = [s.read() for s in self.sensors]\n",
        "        # Basic validation: keep only valid readings\n",
        "        valid_readings = [r for r in readings if validate_vitals(r)]\n",
        "        if not valid_readings:\n",
        "            audit_event({'type': 'no_valid_readings', 'patient_id': self.patient.patient_id})\n",
        "            logging.warning(\"No valid sensor readings for patient %s\", self.patient.patient_id)\n",
        "            return\n",
        "\n",
        "        # Aggregate by median for each metric\n",
        "        def median(xs):\n",
        "            xs_sorted = sorted(xs)\n",
        "            n = len(xs_sorted)\n",
        "            return xs_sorted[n//2] if n % 2 == 1 else (xs_sorted[n//2 - 1] + xs_sorted[n//2]) / 2\n",
        "\n",
        "        hr_vals = [r.heart_rate for r in valid_readings if r.heart_rate is not None]\n",
        "        spo2_vals = [r.spo2 for r in valid_readings if r.spo2 is not None]\n",
        "        sbp_vals = [r.systolic_bp for r in valid_readings if r.systolic_bp is not None]\n",
        "        dbp_vals = [r.diastolic_bp for r in valid_readings if r.diastolic_bp is not None]\n",
        "\n",
        "        merged = Vitals(\n",
        "            heart_rate=(median(hr_vals) if hr_vals else None),\n",
        "            spo2=(median(spo2_vals) if spo2_vals else None),\n",
        "            systolic_bp=(median(sbp_vals) if sbp_vals else None),\n",
        "            diastolic_bp=(median(dbp_vals) if dbp_vals else None),\n",
        "            sensor_id=\"merged\",\n",
        "            timestamp=time.time()\n",
        "        )\n",
        "\n",
        "        reason = self.evaluate(merged)\n",
        "        audit_event({'type': 'evaluation', 'patient_id': self.patient.patient_id, 'vitals': merged.__dict__, 'reason': reason})\n",
        "        if reason:\n",
        "            # local alarm immediately\n",
        "            self.alerting.local_alarm(self.patient, merged, reason)\n",
        "            self.alerting.notify_nurse_station(self.patient, merged, reason)\n",
        "\n",
        "            # if configured to confirm, re-check before escalation\n",
        "            if self.patient.confirmation_required:\n",
        "                confirmed = self.redundant_confirm(lambda: random.choice(self.sensors).read(), reason)\n",
        "                if not confirmed:\n",
        "                    logging.info(\"Abnormality not confirmed by redundant reads for %s: %s\", self.patient.patient_id, reason)\n",
        "                    audit_event({'type': 'unconfirmed_alert', 'patient_id': self.patient.patient_id, 'reason': reason})\n",
        "                    return\n",
        "            # escalate\n",
        "            alert_id = self.alerting.escalate_to_physician(self.patient, merged, reason)\n",
        "            # Important: require human acknowledgement for critical actions (e.g., medication changes)\n",
        "            logging.info(\"Awaiting human acknowledgement for alert %s\", alert_id)\n",
        "\n",
        "    def start(self, interval: float = 2.0):\n",
        "        if self.running:\n",
        "            return\n",
        "        self.running = True\n",
        "        def run_loop():\n",
        "            while self.running:\n",
        "                try:\n",
        "                    self.check_once()\n",
        "                    self.last_heartbeat = time.time()\n",
        "                except Exception as ex:\n",
        "                    audit_event({'type': 'monitor_error', 'patient_id': self.patient.patient_id, 'error': str(ex)})\n",
        "                    logging.exception(\"Error in monitor check: %s\", ex)\n",
        "                time.sleep(interval)\n",
        "        self.thread = threading.Thread(target=run_loop, daemon=True)\n",
        "        self.thread.start()\n",
        "        audit_event({'type': 'monitor_started', 'patient_id': self.patient.patient_id})\n",
        "\n",
        "    def stop(self):\n",
        "        self.running = False\n",
        "        if self.thread:\n",
        "            self.thread.join(timeout=2.0)\n",
        "        audit_event({'type': 'monitor_stopped', 'patient_id': self.patient.patient_id})\n",
        "\n",
        "# ----------------------------\n",
        "# System-level watchdog\n",
        "# ----------------------------\n",
        "class Watchdog:\n",
        "    \"\"\"Checks heartbeats of monitors and reports system-level failures.\"\"\"\n",
        "    def __init__(self, monitors: List[Monitor], interval: float = 10.0, heartbeat_timeout: float = 15.0):\n",
        "        self.monitors = monitors\n",
        "        self.interval = interval\n",
        "        self.heartbeat_timeout = heartbeat_timeout\n",
        "        self.running = False\n",
        "        self.thread: Optional[threading.Thread] = None\n",
        "    def start(self):\n",
        "        self.running = True\n",
        "        def loop():\n",
        "            while self.running:\n",
        "                now = time.time()\n",
        "                for m in self.monitors:\n",
        "                    if now - m.last_heartbeat > self.heartbeat_timeout:\n",
        "                        audit_event({'type': 'watchdog_alert', 'patient_id': m.patient.patient_id, 'last_heartbeat': m.last_heartbeat})\n",
        "                        logging.error(\"Monitor heartbeat missing for %s (last %s seconds ago)\", m.patient.patient_id, int(now - m.last_heartbeat))\n",
        "                time.sleep(self.interval)\n",
        "        self.thread = threading.Thread(target=loop, daemon=True)\n",
        "        self.thread.start()\n",
        "    def stop(self):\n",
        "        self.running = False\n",
        "        if self.thread:\n",
        "            self.thread.join(timeout=2.0)\n",
        "\n",
        "# ----------------------------\n",
        "# Demo / Example usage\n",
        "# ----------------------------\n",
        "def demo_run(duration_seconds: float = 30):\n",
        "    # Setup demo patient + sensors\n",
        "    patient = PatientConfig(patient_id=\"P-001\", name=\"Demo Patient\")\n",
        "    base = {'heart_rate': 72, 'spo2': 97, 'systolic_bp': 120, 'diastolic_bp': 78}\n",
        "    sensors = [\n",
        "        SensorSimulator(sensor_id=\"S1\", base_vitals=base, noise=0.03),\n",
        "        SensorSimulator(sensor_id=\"S2\", base_vitals=base, noise=0.06),\n",
        "        SensorSimulator(sensor_id=\"S3\", base_vitals=base, noise=0.04)\n",
        "    ]\n",
        "    alerting = AlertingSystem()\n",
        "    monitor = Monitor(patient, sensors, alerting, confirm_attempts=2, confirm_interval=0.5)\n",
        "    monitor.start(interval=2.0)\n",
        "    watchdog = Watchdog([monitor], interval=5.0, heartbeat_timeout=8.0)\n",
        "    watchdog.start()\n",
        "\n",
        "    # Run for some time; occasionally inject abnormal conditions\n",
        "    start = time.time()\n",
        "    while time.time() - start < duration_seconds:\n",
        "        # Occasionally simulate a physiologic deterioration in sensor base\n",
        "        if random.random() < 0.05:\n",
        "            logging.info(\"Simulating acute desaturation event in sensor S1\")\n",
        "            sensors[0].base['spo2'] = max(60, sensors[0].base['spo2'] - random.uniform(10, 30))\n",
        "        # Occasionally restore\n",
        "        if random.random() < 0.02:\n",
        "            sensors[0].base['spo2'] = 97\n",
        "\n",
        "        time.sleep(1.0)\n",
        "\n",
        "    monitor.stop()\n",
        "    watchdog.stop()\n",
        "    logging.info(\"Demo finished\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo_run(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci9Up-SDJC6o",
        "outputId": "9b021377-74eb-4a3a-9463-c76c705ab43e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1084721305.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  event['timestamp'] = datetime.utcnow().isoformat() + 'Z'\n",
            "WARNING:root:LOCAL ALARM for P-001: spo2_low | Vitals(heart_rate=72.7, spo2=85.9, systolic_bp=120.8, diastolic_bp=80.3, sensor_id='merged', timestamp=1763455582.3436759)\n",
            "CRITICAL:root:ESCALATE [ffdd0910-5827-4f25-9489-24181027470a] P-001 -> physician: spo2_low\n",
            "WARNING:root:LOCAL ALARM for P-001: spo2_low | Vitals(heart_rate=71.2, spo2=83.0, systolic_bp=116.9, diastolic_bp=77.2, sensor_id='merged', timestamp=1763455585.3472931)\n",
            "CRITICAL:root:ESCALATE [b8b82a88-5768-470a-a514-35a32112f8fd] P-001 -> physician: spo2_low\n",
            "WARNING:root:LOCAL ALARM for P-001: spo2_low | Vitals(heart_rate=72.9, spo2=81.9, systolic_bp=120.0, diastolic_bp=79.6, sensor_id='merged', timestamp=1763455588.3506117)\n",
            "CRITICAL:root:ESCALATE [51a20039-7eed-4c15-85f3-470a20407df7] P-001 -> physician: spo2_low\n",
            "WARNING:root:LOCAL ALARM for P-001: spo2_low | Vitals(heart_rate=70.6, spo2=82.1, systolic_bp=120.4, diastolic_bp=77.5, sensor_id='merged', timestamp=1763455591.3539553)\n",
            "CRITICAL:root:ESCALATE [9f4b7d64-07a1-4534-a6f7-a30b84b5f261] P-001 -> physician: spo2_low\n",
            "WARNING:root:LOCAL ALARM for P-001: spo2_low | Vitals(heart_rate=71.4, spo2=83.4, systolic_bp=116.8, diastolic_bp=77.0, sensor_id='merged', timestamp=1763455594.3603575)\n",
            "CRITICAL:root:ESCALATE [68c5517e-58a2-44e7-88fd-e2b68aa6e797] P-001 -> physician: spo2_low\n",
            "WARNING:root:LOCAL ALARM for P-001: spo2_low | Vitals(heart_rate=72.2, spo2=64.1, systolic_bp=118.2, diastolic_bp=79.8, sensor_id='merged', timestamp=1763455597.364793)\n",
            "CRITICAL:root:ESCALATE [4df72737-c5d6-44e5-a47f-3cbb1221beac] P-001 -> physician: spo2_low\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION :The code intentionally includes safety patterns (redundant confirmation, audit trail, alerts that require human acknowledgement) so you can analyze who should be accountable when things go wrong.\n",
        "\n",
        "Consider failure modes: sensor hardware failure, network partition (alerts not delivered), software bug in evaluation logic, race conditions, corrupt audit log, or human factors (missed acknowledgement).\n",
        "\n",
        "Points to discuss: regulatory compliance (medical device standards), testing requirements, validation by clinicians, integration testing with real sensors, incident response, and whether AI-generated code should be allowed to run without human oversight.\n",
        "\n",
        "The code contains clear integration hook points (alerting methods) — these are places where secure, auditable channels must be used in a real hospital (and where a human operator must be present"
      ],
      "metadata": {
        "id": "UBozg4HVJxb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 – Limitations of AI in Critical Systems\n",
        "•\tAsk AI to generate code for a life-critical application (e.g., railway signaling, medical diagnosis).\n",
        "•\tDiscuss:\n",
        "o\tShould AI code be used directly in such systems?\n",
        "o\tWhat level of human oversight is mandatory?\n",
        "o\tHow do we balance efficiency vs safety?\n",
        "\n"
      ],
      "metadata": {
        "id": "DwY_ynjnJ8X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT :Ask the AI to generate code for a life-critical system (such as railway signaling, medical diagnosis, or emergency alerting). After obtaining the code, analyze whether AI-generated code should ever be used directly in such safety-critical applications. Discuss what level of human oversight, verification, validation, and testing is mandatory. Evaluate how organizations should balance efficiency and automation against safety, reliability, and ethical responsibility. Provide a detailed reflection on the risks, limitations, and safeguards required when involving AI in life-critical systems.\""
      ],
      "metadata": {
        "id": "JNAKtQddJ-xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Railway Signaling Safety Check (Demo Only – Not Real-World Safe)\n",
        "\n",
        "tracks = {\n",
        "    \"Track1\": {\"occupied\": False, \"signal\": \"GREEN\"},\n",
        "    \"Track2\": {\"occupied\": True,  \"signal\": \"RED\"},\n",
        "}\n",
        "\n",
        "def update_signal(track_name, is_occupied):\n",
        "    if is_occupied:\n",
        "        tracks[track_name][\"signal\"] = \"RED\"\n",
        "    else:\n",
        "        tracks[track_name][\"signal\"] = \"GREEN\"\n",
        "    return tracks[track_name][\"signal\"]\n",
        "\n",
        "def check_for_collision():\n",
        "    for name, data in tracks.items():\n",
        "        if data[\"occupied\"] and data[\"signal\"] == \"GREEN\":\n",
        "            print(f\"⚠️ DANGER: Incorrect green signal on {name}!\")\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Demo\n",
        "print(\"Track status and signals:\")\n",
        "for t in tracks:\n",
        "    print(t, tracks[t])\n",
        "\n",
        "collision = check_for_collision()\n",
        "if collision:\n",
        "    print(\"Emergency alert triggered!\")\n",
        "else:\n",
        "    print(\"System operating normally.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bht0dBZnKHFz",
        "outputId": "4c740814-de59-4b99-ba9b-e63f2482b875"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Track status and signals:\n",
            "Track1 {'occupied': False, 'signal': 'GREEN'}\n",
            "Track2 {'occupied': True, 'signal': 'RED'}\n",
            "System operating normally.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : Certainly! The code in cell bht0dBZnKHFz is a very simplified Python script designed as a demo for a railway signaling safety check. It's clearly marked as 'Demo Only – Not Real-World Safe', emphasizing its illustrative nature.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "tracks Dictionary: This dictionary represents the state of different railway tracks. Each track (e.g., 'Track1', 'Track2') has two properties:\n",
        "\n",
        "occupied: A boolean indicating whether a train is currently on the track.\n",
        "signal: The current signal displayed ('GREEN' or 'RED').\n",
        "update_signal Function: This function takes a track_name and a boolean is_occupied. It updates the signal for that track: if the track is_occupied, the signal is set to 'RED'; otherwise, it's set to 'GREEN'.\n",
        "\n",
        "check_for_collision Function: This is the core safety check. It iterates through all tracks and looks for a dangerous condition: if a track is occupied and its signal is 'GREEN' at the same time, it prints a 'DANGER' warning and returns True, indicating a potential collision scenario.\n",
        "\n",
        "Demo Usage: The script then prints the initial status of the tracks and signals. After that, it calls check_for_collision() to determine if any unsafe conditions exist and reports whether the system is operating normally or if an emergency alert should be triggered.\n",
        "\n",
        "In essence, this code provides a basic, illustrative model of how a railway signaling system might check for a critical safety violation: an occupied track being given a 'GREEN' (clear) signal.\n",
        "\n"
      ],
      "metadata": {
        "id": "KJOglYbiKN1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6 – Ethical Use of AI-Generated Code\n",
        "•\tStudents analyze real-world cases (e.g., plagiarism, copyright violation, misuse of open-source code).\n",
        "•\tIdentify best practices for ethically using AI code:\n",
        "o\tAttribution\n",
        "o\tVerification\n",
        "o\tResponsible deployment\n"
      ],
      "metadata": {
        "id": "fH4MntuoKU4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPT : \"Research and analyze real-world cases where AI-generated code raised ethical issues such as plagiarism, copyright violations, license conflicts, or misuse of open-source code. Then evaluate how developers should ethically use AI-generated code. Discuss best practices for attribution, verifying correctness and security, checking licensing compatibility, and ensuring responsible deployment. Provide examples, identify risks, and propose clear guidelines for ethical AI-assisted coding.\""
      ],
      "metadata": {
        "id": "Ec5j5ImTKfhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "ai_code_ethics_toolkit.py\n",
        "\n",
        "Small toolkit for ethically handling AI-generated code in a repo/workspace.\n",
        "\n",
        "Features:\n",
        "- insert_attribution(file_path, source_info): prepend attribution comment to a code file\n",
        "- run_license_check(env=\"python\"): run a license scanner (calls pip-licenses) -- requires pip-licenses installed\n",
        "- run_static_analysis(target_path): run flake8 + bandit on target path (requires flake8, bandit)\n",
        "- run_unit_tests(test_dir): run pytest on tests directory\n",
        "- generate_remediation_patch(orig_file, patched_text, patch_file): save a unified-diff-like patch (simple)\n",
        "- simple CLI to run checks\n",
        "\n",
        "Note: this toolkit shells out to common tools (pip-licenses, flake8, bandit, pytest). Install them in your environment:\n",
        "  pip install pip-licenses flake8 bandit pytest\n",
        "This script is for educational/demo use only.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional\n",
        "import difflib\n",
        "import tempfile\n",
        "\n",
        "ATTRIBUTION_TEMPLATE = \"\"\"# -------------------------------------------------------------------------\n",
        "# AI-GENERATED CODE: Attribution\n",
        "# Source: {source}\n",
        "# Prompt summary: {prompt}\n",
        "# Date: {date}\n",
        "# Notes: Reviewed by: {reviewer} | Review date: {review_date}\n",
        "# License considerations: {license_notes}\n",
        "# -------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "def insert_attribution(file_path: str, source_info: Dict[str, str], overwrite: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    Prepend an attribution block to a source file unless it already exists.\n",
        "    source_info keys: source, prompt, date, reviewer, review_date, license_notes\n",
        "    \"\"\"\n",
        "    p = Path(file_path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(file_path)\n",
        "    text = p.read_text(encoding='utf-8')\n",
        "    # Simple detection: don't add if attribution header already present\n",
        "    if text.startswith(\"# -------------------------------------------------------------------------\"):\n",
        "        print(f\"[skip] Attribution already present in {file_path}\")\n",
        "        return\n",
        "    header = ATTRIBUTION_TEMPLATE.format(\n",
        "        source=source_info.get(\"source\", \"AI model\"),\n",
        "        prompt=source_info.get(\"prompt\", \"N/A\").replace(\"\\n\", \" \"),\n",
        "        date=source_info.get(\"date\", \"\"),\n",
        "        reviewer=source_info.get(\"reviewer\", \"TBD\"),\n",
        "        review_date=source_info.get(\"review_date\", \"\"),\n",
        "        license_notes=source_info.get(\"license_notes\", \"Check licenses\")\n",
        "    )\n",
        "    new_text = header + \"\\n\" + text\n",
        "    if overwrite:\n",
        "        p.write_text(new_text, encoding='utf-8')\n",
        "    else:\n",
        "        # safe-write to temp + replace\n",
        "        with tempfile.NamedTemporaryFile('w', delete=False, encoding='utf-8') as tf:\n",
        "            tf.write(new_text)\n",
        "            tmp = tf.name\n",
        "        os.replace(tmp, p)\n",
        "    print(f\"[ok] Attribution inserted into {file_path}\")\n",
        "\n",
        "def run_subprocess(cmd: list[str], cwd: Optional[str] = None, capture: bool = False) -> subprocess.CompletedProcess:\n",
        "    \"\"\"Helper to run subprocess and return CompletedProcess.\"\"\"\n",
        "    try:\n",
        "        if capture:\n",
        "            return subprocess.run(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, check=False, text=True)\n",
        "        else:\n",
        "            return subprocess.run(cmd, cwd=cwd, check=False)\n",
        "    except FileNotFoundError as e:\n",
        "        raise RuntimeError(f\"Command not found: {cmd[0]}. Please install required tool.\") from e\n",
        "\n",
        "def run_license_check(env: str = \"python\") -> str:\n",
        "    \"\"\"\n",
        "    Run dependency license check.\n",
        "    For Python: relies on 'pip-licenses'. For Node.js you'd use 'license-checker'.\n",
        "    Returns tool stdout text.\n",
        "    \"\"\"\n",
        "    if env == \"python\":\n",
        "        print(\"[info] Running pip-licenses (requires pip-licenses installed)...\")\n",
        "        res = run_subprocess([sys.executable, \"-m\", \"piplicenses\", \"--format=columns\"], capture=True)\n",
        "        return res.stdout\n",
        "    else:\n",
        "        raise NotImplementedError(\"Only 'python' env supported in this demo. For npm use license-checker via npm.\")\n",
        "\n",
        "def run_static_analysis(target_path: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Run flake8 (style) and bandit (security) on target_path.\n",
        "    Returns dict with outputs.\n",
        "    \"\"\"\n",
        "    outputs = {}\n",
        "    print(f\"[info] Running flake8 on {target_path} (requires flake8)...\")\n",
        "    flake = run_subprocess([\"flake8\", target_path], capture=True)\n",
        "    outputs['flake8'] = flake.stdout or \"(no flake8 output)\"\n",
        "    print(f\"[info] Running bandit on {target_path} (requires bandit)...\")\n",
        "    bandit = run_subprocess([\"bandit\", \"-r\", target_path], capture=True)\n",
        "    outputs['bandit'] = bandit.stdout or \"(no bandit output)\"\n",
        "    return outputs\n",
        "\n",
        "def run_unit_tests(test_dir: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Run pytest on the given tests directory. Returns stdout/stderr.\n",
        "    \"\"\"\n",
        "    print(f\"[info] Running pytest on {test_dir} (requires pytest)...\")\n",
        "    res = run_subprocess([\"pytest\", test_dir, \"-q\"], capture=True)\n",
        "    return {\"pytest\": res.stdout}\n",
        "\n",
        "def generate_remediation_patch(orig_file: str, patched_text: str, patch_file: str) -> None:\n",
        "    \"\"\"\n",
        "    Create a small unified-diff-like patch between original file and patched_text.\n",
        "    This is not a git patch, but human-readable diff for assignment submission.\n",
        "    \"\"\"\n",
        "    p = Path(orig_file)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(orig_file)\n",
        "    orig_lines = p.read_text(encoding='utf-8').splitlines(keepends=True)\n",
        "    new_lines = patched_text.splitlines(keepends=True)\n",
        "    diff = difflib.unified_diff(orig_lines, new_lines, fromfile=orig_file, tofile=f\"{orig_file}.patched\", lineterm=\"\")\n",
        "    diff_text = \"\".join(diff)\n",
        "    Path(patch_file).write_text(diff_text, encoding='utf-8')\n",
        "    print(f\"[ok] Remediation patch written to {patch_file}\")\n",
        "\n",
        "# -------------------------\n",
        "# Simple CLI for demonstrations\n",
        "# -------------------------\n",
        "def _demo_usage():\n",
        "    print(\"\"\"\n",
        "ai_code_ethics_toolkit.py - demo usage examples:\n",
        "\n",
        "1) Insert attribution:\n",
        "   from this repo root:\n",
        "     python -c \"from ai_code_ethics_toolkit import insert_attribution; insert_attribution('generated.py', {'source':'ChatGPT', 'prompt':'Sort names and assign grades', 'date':'2025-11-18','reviewer':'Alice','review_date':'2025-11-19','license_notes':'Check dependencies'})\"\n",
        "\n",
        "2) Run license check (Python):\n",
        "     python -c \"from ai_code_ethics_toolkit import run_license_check; print(run_license_check())\"\n",
        "\n",
        "3) Run static analysis:\n",
        "     python -c \"from ai_code_ethics_toolkit import run_static_analysis; print(run_static_analysis('src'))\"\n",
        "\n",
        "4) Run unit tests:\n",
        "     python -c \"from ai_code_ethics_toolkit import run_unit_tests; print(run_unit_tests('tests'))\"\n",
        "\n",
        "5) Generate remediation patch:\n",
        "     python -c \"from ai_code_ethics_toolkit import generate_remediation_patch; orig='generated.py'; new=open(orig).read().replace('password','<REDACTED>'); generate_remediation_patch(orig, new, 'patch.diff')\"\n",
        "\"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Minimal CLI: just print usage if called directly\n",
        "    _demo_usage()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3QBVNRjKhJS",
        "outputId": "f385b296-b499-4eee-9537-e94b514657ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ai_code_ethics_toolkit.py - demo usage examples:\n",
            "\n",
            "1) Insert attribution:\n",
            "   from this repo root:\n",
            "     python -c \"from ai_code_ethics_toolkit import insert_attribution; insert_attribution('generated.py', {'source':'ChatGPT', 'prompt':'Sort names and assign grades', 'date':'2025-11-18','reviewer':'Alice','review_date':'2025-11-19','license_notes':'Check dependencies'})\"\n",
            "\n",
            "2) Run license check (Python):\n",
            "     python -c \"from ai_code_ethics_toolkit import run_license_check; print(run_license_check())\"\n",
            "\n",
            "3) Run static analysis:\n",
            "     python -c \"from ai_code_ethics_toolkit import run_static_analysis; print(run_static_analysis('src'))\"\n",
            "\n",
            "4) Run unit tests:\n",
            "     python -c \"from ai_code_ethics_toolkit import run_unit_tests; print(run_unit_tests('tests'))\"\n",
            "\n",
            "5) Generate remediation patch:\n",
            "     python -c \"from ai_code_ethics_toolkit import generate_remediation_patch; orig='generated.py'; new=open(orig).read().replace('password','<REDACTED>'); generate_remediation_patch(orig, new, 'patch.diff')\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION : Certainly! The code in cell u3QBVNRjKhJS is a Python script named ai_code_ethics_toolkit.py. It's designed to provide a set of utilities for developers to ethically handle and integrate code generated by AI models into their projects. The script aims to address common concerns like attribution, licensing, and code quality.\n",
        "\n",
        "Here's a breakdown of its main functions:\n",
        "\n",
        "insert_attribution(file_path, source_info): This function helps to prepend a standardized attribution comment block to a code file. This block records important details such as the AI source, the prompt used, the generation date, who reviewed the code, and any license considerations. This is crucial for transparency and intellectual property management.\n",
        "\n",
        "run_license_check(env='python'): This utility is designed to help check the licenses of dependencies used in a project. For Python environments, it specifically calls pip-licenses to list and review the licenses of installed packages, which is vital for avoiding license conflicts when using AI-generated code that might pull in various libraries.\n",
        "\n",
        "run_static_analysis(target_path): This function integrates with common static analysis tools like flake8 (for code style and quality) and bandit (for security vulnerabilities). Running these tools on AI-generated code helps developers verify its correctness and identify potential security flaws before deployment.\n",
        "\n",
        "run_unit_tests(test_dir): It provides a way to execute unit tests within a specified directory using pytest. This is essential for ensuring that AI-generated code functions as expected and doesn't introduce regressions.\n",
        "\n",
        "generate_remediation_patch(orig_file, patched_text, patch_file): This function creates a human-readable patch (diff) between an original file and its modified version. This can be useful for documenting changes made during the review and remediation process of AI-generated code.\n",
        "\n",
        "_demo_usage(): The script also includes a demonstration of how these functions can be called and used, typically from a command-line interface.\n",
        "\n",
        "In essence, this toolkit provides practical steps and integrations to encourage responsible development practices when incorporating AI-generated code, emphasizing verification, transparency, and compliance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Dz_NXCtvK13h"
      }
    }
  ]
}